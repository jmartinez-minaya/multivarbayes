
---
title: "Comparison of multivarbayes and brms"
author: "Joaquín Martínez-Minaya"
output: html_document
vignette: >
  %\VignetteIndexEntry{Comparison of multivarbayes and brms}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

## Introduction

This vignette demonstrates the usage and performance comparison between the `multivarbayes` package and the `brms` package for fitting a Bayesian multivariate linear regression model.

### Steps Covered in This Vignette:

1. **Simulate Data**: We will generate data for a multivariate normal regression model with two covariates and three response variables.
2. **Fit Models**: Fit the model using both `multivarbayes` and `brms`.
3. **Compare Posterior Distributions**: We will compare the posterior distributions of the coefficients (`B`) and hyperparameters (`Sigma`).

## Step 1: Simulate Data

We first simulate a dataset that follows a multivariate normal regression model with two covariates and three response variables.

```{r simulate_data}
# Load necessary libraries
library(MASS)
library(multivarbayes)
library(brms)
library(ggplot2)
library(dplyr)
library(tidyr)
library(patchwork)

set.seed(123)  # Set seed for reproducibility

# Simulate data
n <- 1000  # Number of observations
k <- 2    # Number of covariates (excluding intercept)
m <- 3    # Number of response variables

# Covariate matrix with intercept
X <- cbind(1, matrix(rnorm(n * k), n, k))  

# True coefficients
B_true <- matrix(c(0.8, -0.2, 0.5, 1, -1, 0.7), nrow = k + 1, ncol = m)

# Covariance matrix for multivariate normal distribution
Sigma_true <- matrix(c(1, 0.4, 0.2, 0.4, 1, 0.3, 0.2, 0.3, 1), ncol = m)

# Generate response matrix Y
Y <- X %*% B_true + MASS::mvrnorm(n, mu = rep(0, m), Sigma = Sigma_true)

# Combine data into a single data frame
data <- data.frame(cbind(Y, X))
colnames(data) <- c(paste0("Y", 1:m), paste0("X", 0:k))  # Response variables and covariates
```

## Step 2: Fit Models Using `multivarbayes`

We define the model formula and use the `mlvr` function from the `multivarbayes` package to fit the multivariate linear regression model. The model fit returns posterior simulations for the coefficients and hyperparameters, as well as analytic forms of the posterior distributions.

### Default Priors in `multivarbayes`

The `multivarbayes` package uses conjugate priors for both the coefficient matrix \( B \) and the covariance matrix \( \Sigma \).

1. **Prior for the coefficient matrix \( B \)**:

   \[
   B | \Sigma \sim \mathcal{N}(B_0, \Sigma \otimes A^{-1})
   \]

   Where:
   - \( B_0 \) is a matrix of zeros with dimensions \( (k + 1) \times m \), where \( k \) is the number of predictors and \( m \) is the number of response variables.
   - \( A \) is the precision matrix of the covariates, which by default is an identity matrix of size \( (k + 1) \times (k + 1) \).

2. **Prior for the covariance matrix \( \Sigma \)**:

   \[
   \Sigma \sim \text{IW}(\nu_0, V_0)
   \]

   Where:
   - \( \nu_0 = m + 2 \) is the degree of freedom for the inverse-Wishart distribution (this value is set based on \( m \), the number of response variables).
   - \( V_0 \) is the scale matrix, which by default is an identity matrix of size \( m \times m \).

### Default Prior Values:

- \( B_0 = \text{matrix}(0, nrow = k + 1, ncol = m) \)
- \( A = \text{diag}(k + 1) \)
- \( \nu_0 = m + 2 \)
- \( V_0 = \text{diag}(m) \)

These priors assume that, *a priori*, the coefficients of the model are centered at zero with a precision (inverse of the variance) equal to 1 for each covariate. The prior for \( \Sigma \) assumes an identity variance-covariance matrix for the response variables under the inverse-Wishart distribution.


```{r fit_multivarbayes}
# Define formula and fit the model using multivarbayes
formula <- as.matrix(data[, paste0("Y", 1:m)]) ~ X1 + X2
fit_mvbayes <- mlvr(formula, data = data, n_sims = 1000)
summary(fit_mvbayes)
```

## Step 3: Fit Models Using `brms`

We define the same model using the `brms` package and fit it using the `brm` function. We include separate formulas for each response variable and specify a residual correlation structure (`rescor = TRUE`).

```{r fit_brms}
# Define formula and fit the model using brms
brms_formula <- bf(Y1 ~ X1 + X2) + bf(Y2 ~ X1 + X2) + bf(Y3 ~ X1 + X2) + set_rescor(TRUE)
brms_fit <- brm(brms_formula, data = data, chains = 2, cores = 2, iter = 2000)
```



## Step 4: Compare Posterior Distributions

```{r compare_posteriors, fig.width=10, fig.height=8}
# 1. Extract posterior samples from `multivarbayes` for each response variable.
mvbayes_posterior_list <- list()
for (response_var in names(fit_mvbayes$marginals.fixed)) {
  # Extract the data frame for each response variable
  response_samples <- fit_mvbayes$marginals.fixed[[response_var]]
  
  # Convert each column (beta) into long format
  response_long <- response_samples %>%
    pivot_longer(cols = everything(), names_to = "Parameter", values_to = "Value") %>%
    mutate(Response = response_var)
  
  # Add to the list of posterior samples
  mvbayes_posterior_list[[response_var]] <- response_long
}

# Combine all response variables into a single data frame
mvbayes_posterior <- bind_rows(mvbayes_posterior_list)
# Replace (Intercept) with Intercept for consistency
mvbayes_posterior$Parameter <- gsub("\\(Intercept\\)", "Intercept", mvbayes_posterior$Parameter)

# 2. Extract posterior samples from `brms`
# Assuming `brms_fit` is the fitted brms model containing posterior samples
brms_posterior <- posterior_samples(brms_fit) %>%
  pivot_longer(cols = everything(), names_to = "Parameter", values_to = "Value")

# Filter only the beta parameters (including intercepts) and reorganize
beta_parameters <- c("b_Y1_Intercept", "b_Y1_X1", "b_Y1_X2", 
                     "b_Y2_Intercept", "b_Y2_X1", "b_Y2_X2", 
                     "b_Y3_Intercept", "b_Y3_X1", "b_Y3_X2")

brms_posterior <- brms_posterior %>%
  filter(Parameter %in% beta_parameters) %>%
  mutate(Response = substr(Parameter, 3, 4),  # Extract "Y1", "Y2", "Y3"
         Parameter = ifelse(grepl("Intercept", Parameter), "Intercept",
                            ifelse(grepl("X1", Parameter), "X1", "X2")))  # Rename the parameter for consistency

# 3. Create combined density data for each parameter and response variable
combined_density_data <- list()
parameters_to_compare <- c("Intercept", "X1", "X2")

for (response_var in unique(mvbayes_posterior$Response)) {
  for (param in parameters_to_compare) {
    # Filter `multivarbayes` samples for the current response variable and parameter
    mvbayes_samples <- mvbayes_posterior %>%
      filter(Response == response_var, Parameter == param)
    
    # Filter `brms` samples for the current response variable and parameter
    brms_samples <- brms_posterior %>%
      filter(Response == response_var, Parameter == param)
    
    # Check if there are enough points to calculate density in `multivarbayes`
    if (nrow(mvbayes_samples) < 2 || nrow(brms_samples) < 2) {
      next  # Skip if not enough data points
    }
    
    # Calculate densities for `multivarbayes`
    mvbayes_density <- density(mvbayes_samples$Value)
    mvbayes_density_df <- data.frame(
      x = mvbayes_density$x,
      y = mvbayes_density$y,
      Model = "multivarbayes",
      Parameter = param,
      Response = response_var
    )
    
    # Calculate densities for `brms`
    brms_density <- density(brms_samples$Value)
    brms_density_df <- data.frame(
      x = brms_density$x,
      y = brms_density$y,
      Model = "brms",
      Parameter = param,
      Response = response_var
    )
    
    # Combine both densities
    combined_density_data[[paste(response_var, param, sep = "_")]] <- bind_rows(mvbayes_density_df, brms_density_df)
  }
}

# Combine all density data into a single data frame for plotting
combined_density_data_df <- bind_rows(combined_density_data)

# Ensure that intercepts are included in the data frame
combined_density_data_df <- combined_density_data_df %>%
  mutate(Parameter = factor(Parameter, levels = c("Intercept", "X1", "X2")))

# 4. Create a plot using facet_wrap with each row representing a response variable
ggplot(combined_density_data_df, aes(x = x, y = y, color = Model, fill = Model)) +
  geom_line(size = 1.2) +
  geom_area(alpha = 0.2, position = "identity") +
  theme_minimal() +
  labs(title = "Posterior Density Comparison: multivarbayes vs brms",
       x = "Value", y = "Density") +
  theme(legend.position = "top", legend.title = element_text(face = "bold")) +
  scale_color_manual(values = c("blue", "red")) +
  scale_fill_manual(values = c("blue", "red")) +
  facet_wrap(Response ~ Parameter, scales = "free", ncol = 3) +
  guides(fill = guide_legend(title = "Model"), color = guide_legend(title = "Model"))
```



## Step 5: Unified Comparison of Hyperparameters (Correlations and Standard Deviations)
```{r compare_hyperparameters_final, fig.width=12, fig.height=8}
# 1. Convert variances to standard deviations and covariances to correlations in `multivarbayes`
# Extract hyperparameter samples from `multivarbayes`
mvbayes_hyperpar <- fit_mvbayes$marginals.hyperpar

# Calculate standard deviations from variances for sigma2_1, sigma2_2, and sigma2_3
mvbayes_hyperpar <- mvbayes_hyperpar %>%
  mutate(
    sigma_Y1 = sqrt(sigma2_1),  # Convert sigma2_1 (variance) to sigma_Y1 (standard deviation)
    sigma_Y2 = sqrt(sigma2_2),  # Convert sigma2_2 (variance) to sigma_Y2 (standard deviation)
    sigma_Y3 = sqrt(sigma2_3),  # Convert sigma2_3 (variance) to sigma_Y3 (standard deviation)
    # Calculate correlations for the covariances using the corresponding standard deviations
    rho_12 = sigma2_12 / (sigma_Y1 * sigma_Y2),
    rho_13 = sigma2_13 / (sigma_Y1 * sigma_Y3),
    rho_23 = sigma2_23 / (sigma_Y2 * sigma_Y3)
  ) %>%
  dplyr::select(sigma_Y1, sigma_Y2, sigma_Y3, rho_12, rho_13, rho_23)  # Keep only the relevant columns

# Convert mvbayes_hyperpar to long format for plotting
mvbayes_hyperpar_long <- mvbayes_hyperpar %>%
  pivot_longer(cols = everything(), names_to = "Parameter", values_to = "Value") %>%
  mutate(Model = "multivarbayes")  # Add model identifier

# 2. Extract correlations and standard deviations from `brms`
# Convert standard deviations and correlations from brms to the same naming convention as multivarbayes
brms_hyperpar <- posterior_samples(brms_fit, pars = c("sigma_Y1", "sigma_Y2", "sigma_Y3", 
                                                      "rescor__Y1__Y2", "rescor__Y1__Y3", "rescor__Y2__Y3")) %>%
  pivot_longer(cols = everything(), names_to = "Parameter", values_to = "Value") %>%
  mutate(
    Parameter = case_when(
      Parameter == "sigma_Y1" ~ "sigma_Y1",
      Parameter == "sigma_Y2" ~ "sigma_Y2",
      Parameter == "sigma_Y3" ~ "sigma_Y3",
      Parameter == "rescor__Y1__Y2" ~ "rho_12",
      Parameter == "rescor__Y1__Y3" ~ "rho_13",
      Parameter == "rescor__Y2__Y3" ~ "rho_23",
      TRUE ~ Parameter
    )
  )

# Add model identifier to brms hyperparameters
brms_hyperpar$Model <- "brms"

# 3. Combine `multivarbayes` and `brms` hyperparameters for comparison
combined_hyperpar <- bind_rows(mvbayes_hyperpar_long, brms_hyperpar)

# Ensure factors are correctly ordered and consistent
combined_hyperpar$Parameter <- factor(combined_hyperpar$Parameter, levels = unique(combined_hyperpar$Parameter))

# 4. Plot the comparison of hyperparameters (correlations and standard deviations) with ggplot
ggplot(combined_hyperpar, aes(x = Value, fill = Model, color = Model)) +
  geom_density(alpha = 0.3, size = 1.2) +
  facet_wrap(~ Parameter, scales = "free", ncol = 3) +
  labs(title = "Comparison of Hyperparameters (Correlation and Standard Deviations) between multivarbayes and brms",
       x = "Value", y = "Density") +
  theme_minimal() +
  scale_fill_manual(values = c("blue", "red")) +
  scale_color_manual(values = c("blue", "red")) +
  theme(legend.position = "top", legend.title = element_text(face = "bold")) +
  guides(fill = guide_legend(title = "Model"), color = guide_legend(title = "Model"))
```



# Posterior predictive distribution

In this step, we compare the **posterior predictive distributions** of the `multivarbayes` and `brms` models for a set of new data points. We will generate predictive samples using each model and plot the distributions for visual comparison.

## Generate New Data Points for Prediction

We will use the first three rows of the original dataset as new data points for prediction.

```{r generate_new_data}
# Select the first 3 rows from the dataset for prediction
newdata <- data[1:3, c("X1", "X2")]

# True values for the selected observations
newdata_real <- data[1:3, c("Y1", "Y2", "Y3")]
```

## Generate Predictions Using `multivarbayes`

We use the `predict` function from the `multivarbayes` package to generate the posterior predictive samples for the new data points.

```{r multivarbayes_predictions}
# Generate predictions using `multivarbayes`
mvbayes_predictions <- predict(fit_mvbayes, newdata = newdata)
```

## Generate Predictions Using `brms`

We use the `posterior_predict` function from `brms` to generate the posterior predictive samples for the new data points. This function returns a matrix where each column corresponds to the predictive samples for each observation.

```{r brms_predictions}
# Generate predictions using `brms`
brms_predictions <- posterior_predict(brms_fit, newdata = newdata)
```

## Format the Predictions for Comparison

We need to reformat the predictions obtained from both models into a comparable format. For each model, we extract the simulated predictive samples and organize them into a long format data frame.

```{r format_predictions}
# 1. Format `multivarbayes` predictive samples
mvbayes_predicted_samples <- mvbayes_predictions$marginals
mvbayes_predicted_df <- data.frame()

# Loop through each response variable to extract samples
for (j in 1:length(mvbayes_predicted_samples)) {
  current_response <- mvbayes_predicted_samples[[j]]  # Matrix of simulations for the j-th response
  for (i in 1:nrow(current_response)) {
    current_sample <- current_response[i, ]  # All simulations for the i-th observation
    mvbayes_predicted_df <- rbind(mvbayes_predicted_df,
                                  data.frame(Observation = paste0("Obs_", i),
                                             Response = paste0("Y", j),
                                             Value = current_sample,
                                             Model = "multivarbayes"))
  }
}

# 2. Format `brms` predictions
brms_predicted_df <- data.frame()

# Adjust `brms_predictions` to match the required dimensions: (n_samples, n_responses, n_observations)
n_responses <- ncol(newdata_real)  # Number of response variables (Y1, Y2, Y3)
n_observations <- nrow(newdata)    # Number of new observations

# Convert `brms_predictions` to a 3D array for better manipulation
brms_predictions_array <- array(brms_predictions, dim = c(nrow(brms_predictions), n_responses, n_observations))

# Loop through each observation and response variable to format the samples
for (obs in 1:n_observations) {
  for (resp in 1:n_responses) {
    # Extract samples for the current observation and response variable
    current_sample <- brms_predictions_array[, resp, obs]
    # Create a data frame for the current sample
    brms_predicted_df <- rbind(brms_predicted_df,
                               data.frame(Observation = paste0("Obs_", obs),
                                          Response = paste0("Y", resp),
                                          Value = current_sample,
                                          Model = "brms"))
  }
}
```

## Combine Predictions and Create a Data Frame for Real Values

We combine the predictions from both models into a single data frame. Additionally, we create a data frame to hold the real observed values for comparison.

```{r combine_predictions}
# Combine both predictions data frames into one for comparison
combined_predictions_df <- bind_rows(mvbayes_predicted_df, brms_predicted_df)

# Create a data frame for the real observed values
real_values_df <- data.frame(
  Observation = rep(paste0("Obs_", 1:3), each = ncol(newdata_real)),
  Response = rep(paste0("Y", 1:ncol(newdata_real)), times = 3),
  Value = as.vector(t(newdata_real)),
  Model = "Real"
)
```

## Plot the Predictive Distributions for Comparison

We plot the predictive distributions using `ggplot2`. Each facet represents a different response variable and observation, allowing us to visually compare the predictive distributions between the `multivarbayes` and `brms` models, along with the true observed values.

```{r plot_predictions, fig.width=12, fig.height=8}
ggplot(combined_predictions_df, aes(x = Value, fill = Model, color = Model)) +
  geom_density(alpha = 0.3, size = 1.2) +
  facet_wrap(Response ~ Observation, scales = "free", ncol = 3) +
  geom_vline(data = real_values_df, aes(xintercept = Value, color = Model), linetype = "dashed", size = 1.2) +
  labs(title = "Posterior Predictive Distribution Comparison",
       x = "Predicted Value", y = "Density") +
  theme_minimal() +
  scale_fill_manual(values = c("blue", "red", "green")) +
  scale_color_manual(values = c("blue", "red", "green")) +
  theme(legend.position = "top", legend.title = element_text(face = "bold")) +
  guides(fill = guide_legend(title = "Model"), color = guide_legend(title = "Model"))
```


In this step, we have compared the posterior predictive distributions of `multivarbayes` and `brms` models for three new observations. The plot provides insights into the differences and similarities between the two models in terms of predictive accuracy and uncertainty.



